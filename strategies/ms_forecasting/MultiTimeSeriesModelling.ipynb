{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from skforecast.plot import set_dark_theme\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn\n",
    "import skforecast\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from skforecast.recursive import ForecasterRecursive, ForecasterRecursiveMultiSeries\n",
    "from skforecast.model_selection import (\n",
    "    TimeSeriesFold,\n",
    "    OneStepAheadFold,\n",
    "    backtesting_forecaster,\n",
    "    bayesian_search_forecaster,\n",
    "    backtesting_forecaster_multiseries,\n",
    "    bayesian_search_forecaster_multiseries\n",
    ")\n",
    "from skforecast.preprocessing import RollingFeatures, series_long_to_dict, exog_long_to_dict\n",
    "from skforecast.exceptions import OneStepAheadValidationWarning\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ResourceWarning)\n",
    "\n",
    "colourOrangeBold = \"\\033[1m\\033[38;5;208m\"\n",
    "colourReset = \"\\033[0m\"\n",
    "\n",
    "print(f\"{colourOrangeBold}Version skforecast: {skforecast.__version__}{colourReset}\")\n",
    "print(f\"{colourOrangeBold}Version scikit-learn: {sklearn.__version__}{colourReset}\")\n",
    "print(f\"{colourOrangeBold}Version pandas: {pd.__version__}{colourReset}\")\n",
    "print(f\"{colourOrangeBold}Version numpy: {np.__version__}{colourReset}\")\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve()\n",
    "while project_root.name != \"Algothon-2025\" and project_root != project_root.parent:\n",
    "    project_root = project_root.parent\n",
    "\n",
    "os.chdir(project_root)\n",
    "print(\"Working directory set to:\", os.getcwd())\n",
    "\n",
    "set_dark_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Set Training, Cross Validation and Testing Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START = 20\n",
    "TRAIN_END = 600\n",
    "VAL_END = 675"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Import our price data: Prices are what we are predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRICES DATA:\n",
    "data = pd.read_csv(\"./sourceCode/prices.txt\", sep=r'\\s+', header=None)\n",
    "print(f\"{colourOrangeBold}Shape: {data.shape}{colourReset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Add column names to prices data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index.name = 'day'\n",
    "data.columns = [f\"inst_{i}\" for i in range(data.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Split data into correct splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA SPLITTING:\n",
    "data_train = data.loc[TRAIN_START:TRAIN_END - 1].copy()\n",
    "data_val   = data.loc[TRAIN_END:VAL_END - 1].copy()\n",
    "data_test  = data.loc[VAL_END:].copy()\n",
    "\n",
    "print(f\"Train days      : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Validation days : {data_val.index.min()} --- {data_val.index.max()}  (n={len(data_val)})\")\n",
    "print(f\"Test days       : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Plot prices data for a few instruments for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumentCount = 4\n",
    "\n",
    "fig, axs = plt.subplots(instrumentCount, 1, figsize=(7, 5), sharex=True)\n",
    "data.iloc[:, :instrumentCount].plot(\n",
    "    legend=True,\n",
    "    subplots=True,\n",
    "    title='First 4 Instruments Prices Over Time',\n",
    "    ax=axs,\n",
    "    linewidth=1\n",
    ")\n",
    "# Add vertical lines at training and validation split\n",
    "for ax in axs:\n",
    "    ax.axvline(x=TRAIN_END, color='white', linestyle='--', linewidth=1)\n",
    "    ax.axvline(x=VAL_END, color='white', linestyle='--', linewidth=1)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Train a forecaster that predicts prices for individual instruments for a baseline reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "mse_values = []\n",
    "predictions = {}\n",
    "\n",
    "for i, item in enumerate(tqdm(data.columns)):\n",
    "    # Define forecaster\n",
    "    window_features = RollingFeatures(stats=['mean', 'min', 'max'], window_sizes=7)\n",
    "\n",
    "    forecaster = ForecasterRecursive(\n",
    "        regressor=HistGradientBoostingRegressor(random_state=8523),\n",
    "        lags=20,\n",
    "        window_features=window_features\n",
    "    )\n",
    "\n",
    "    # Backtesting forecaster\n",
    "    cv = TimeSeriesFold(\n",
    "        steps=1,\n",
    "        initial_train_size=len(data_train) + len(data_val),\n",
    "        refit=False,\n",
    "    )\n",
    "\n",
    "    metric, preds = backtesting_forecaster(\n",
    "        forecaster=forecaster,\n",
    "        y=data[item],\n",
    "        cv=cv,\n",
    "        metric='mean_squared_error',\n",
    "        show_progress=False\n",
    "    )\n",
    "\n",
    "    items.append(item)\n",
    "    mse_values.append(metric.at[0, 'mean_squared_error'])\n",
    "    predictions[item] = preds\n",
    "\n",
    "# Results\n",
    "uni_series_mse = pd.Series(\n",
    "    data=mse_values,\n",
    "    index=items,\n",
    "    name='uni_series_mse'\n",
    ")\n",
    "\n",
    "print(f\"{colourOrangeBold}========================{colourReset}\")\n",
    "print(uni_series_mse.head())\n",
    "print(f\"{colourOrangeBold}========================{colourReset}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Train a global / multi time series predictor that takes into account instrument correlation (Evaluated with the same backtester as the single instrument predictor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(data.columns)\n",
    "\n",
    "# Define forecaster\n",
    "window_features = RollingFeatures(stats=['mean', 'min', 'max'], window_sizes=14)\n",
    "forecaster_ms = ForecasterRecursiveMultiSeries(\n",
    "    regressor           =GradientBoostingRegressor(random_state=8523), # ~ 20 seconds\n",
    "    # regressor           =HistGradientBoostingRegressor(random_state=8523), # Much quicker, slightly less accurate, nan safe\n",
    "    lags                =20,\n",
    "    encoding            ='ordinal',\n",
    "    transformer_series  =StandardScaler(),\n",
    "    window_features     =window_features,\n",
    ")\n",
    "\n",
    "# Backtesting forecaster for all items\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size  =len(data_train) + len(data_val),\n",
    "    steps               =1,   # Predict 7 steps ahead\n",
    "    refit               =True # Retrain at each split\n",
    ")\n",
    "\n",
    "multi_series_mse, predictions_ms = backtesting_forecaster_multiseries(\n",
    "    forecaster          =forecaster_ms,\n",
    "    series              =data,\n",
    "    levels              =items,\n",
    "    cv                  =cv,\n",
    "    metric              ='mean_squared_error',\n",
    ")\n",
    "\n",
    "# Results\n",
    "display(multi_series_mse.head(5))\n",
    "display(predictions_ms.head(5))\n",
    "\n",
    "predictions_ms = predictions_ms.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Compare the global to unique predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_series_mse = multi_series_mse.set_index('levels')\n",
    "multi_series_mse.columns = ['multi_series_mse']\n",
    "\n",
    "results = pd.concat((uni_series_mse, multi_series_mse), axis=1)\n",
    "results['improvement'] = results.eval('uni_series_mse - multi_series_mse')\n",
    "results['improvement_(%)'] = 100 * results.eval('(uni_series_mse - multi_series_mse) / uni_series_mse')\n",
    "results = results.round(2)\n",
    "\n",
    "display(results.style.bar(subset=['improvement_(%)'], align='mid', color=['#d65f5f', '#5fba7d']))\n",
    "display(results[['improvement', 'improvement_(%)']].agg(['mean', 'min', 'max']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Using global predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPredictedVsActual(predictions_input, instrument):\n",
    "    df_preds = predictions_input.copy().rename(columns={\"index\": \"time\"})\n",
    "    df_inst_preds = df_preds[df_preds[\"level\"] == instrument]\n",
    "    days_predicted = df_inst_preds[\"time\"]\n",
    "    df_actual = data[[instrument]].copy()\n",
    "    df_actual[\"time\"] = df_actual.index\n",
    "    df_actual = df_actual.rename(columns={instrument: \"actual\"})\n",
    "    df_actual = df_actual[df_actual[\"time\"].isin(days_predicted)]\n",
    "    df_plot = df_inst_preds.merge(df_actual, on=\"time\")\n",
    "    display(df_plot)\n",
    "    # Step 4: Plot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(df_plot[\"time\"], df_plot[\"actual\"], label=\"Actual Price\", color='dodgerblue')\n",
    "    plt.plot(df_plot[\"time\"], df_plot[\"pred\"], label=\"Predicted Price\", color='orange')\n",
    "    plt.title(f\"Predicted vs Actual Prices for {instrument}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotPredictedVsActual(predictions_ms, \"inst_0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Above looks decent but also a bit shite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "**Now going to try adding more greeks to use in the model as exogenous features**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get exog features in a dictionary\n",
    "greeksFilePaths = sorted(glob.glob(\"./greeks/greeksData_750Days/*.npy\"))\n",
    "feature_names = [os.path.splitext(os.path.basename(f))[0] for f in greeksFilePaths]\n",
    "\n",
    "exog_array = np.stack([np.load(f) for f in greeksFilePaths], axis=-1)\n",
    "\n",
    "exog_dict = {\n",
    "    f\"inst_{i}\": pd.DataFrame(exog_array[:, i, :], columns=feature_names)\n",
    "    for i in range(exog_array.shape[1])\n",
    "}\n",
    "\n",
    "print(f\"{colourOrangeBold}Built exog_dict with {len(exog_dict)} instruments, each shape {exog_dict['inst_0'].shape}{colourReset}\")\n",
    "print(\"Features:\", feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Create our forecaster including these exogenous features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster_ms_greeks = ForecasterRecursiveMultiSeries(\n",
    "    regressor           = GradientBoostingRegressor(random_state=8523),\n",
    "    lags                = 20,\n",
    "    transformer_series  = StandardScaler(),\n",
    "    transformer_exog    = StandardScaler(),  # Standardise the Greek features\n",
    ")\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size = len(data_train) + len(data_val),\n",
    "    steps              = 1,\n",
    "    refit              = True\n",
    ")\n",
    "\n",
    "# Backtest\n",
    "multi_series_mse_greeks, predictions_ms_greeks = backtesting_forecaster_multiseries(\n",
    "    forecaster = forecaster_ms_greeks,\n",
    "    series     = data,\n",
    "    exog       = exog_dict,\n",
    "    levels     = list(data.columns),\n",
    "    cv         = cv,\n",
    "    metric     = \"mean_squared_error\"\n",
    ")\n",
    "\n",
    "display(multi_series_mse_greeks.head())\n",
    "display(predictions_ms_greeks.head())\n",
    "\n",
    "multi_series_mse_greeks = multi_series_mse_greeks.rename(columns={\"mean_squared_error\": \"multi_series_mse_greeks\"})\n",
    "predictions_ms_greeks = predictions_ms_greeks.reset_index()\n",
    "predictions_ms_greeks = predictions_ms_greeks.rename(columns={\"index\": \"time\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Compare new predictions and plot new predictions vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_series_mse_greeks = multi_series_mse_greeks.set_index(\"levels\")\n",
    "# Join them\n",
    "results_greeks = pd.concat((multi_series_mse, multi_series_mse_greeks), axis=1)\n",
    "\n",
    "# Calculate improvements\n",
    "results_greeks['improvement'] = results_greeks.eval('multi_series_mse - multi_series_mse_greeks')\n",
    "results_greeks['improvement_(%)'] = 100 * results_greeks['improvement'] / results_greeks['multi_series_mse']\n",
    "results_greeks = results_greeks.round(2)\n",
    "\n",
    "# Display the goods\n",
    "display(results_greeks.style.bar(subset=['improvement_(%)'], align='mid', color=['#d65f5f', '#5fba7d']))\n",
    "display(results_greeks[['improvement', 'improvement_(%)']].agg(['mean', 'min', 'max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotPredictedVsActual(predictions_ms_greeks, \"inst_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# Now to try and predict log returns instead of prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "logReturns_np = np.load(\"./greeks/greeksData_750Days/LogReturns_lookback=1_750_day_data.npy\")\n",
    "logReturns = pd.DataFrame(logReturns_np)\n",
    "\n",
    "logReturns.columns = [f\"inst_{i}\" for i in range(logReturns.shape[1])]\n",
    "\n",
    "print(f\"{colourOrangeBold}Log returns shape = {colourReset}{logReturns.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Create exogenous data (now with prices, laggedPrices and without logReturns (logReturns is used in predictions by lag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = sorted(glob.glob(\"./greeks/greeksData_750Days/*.npy\"))\n",
    "\n",
    "feature_paths = [\n",
    "    p for p in all_paths\n",
    "    if 'LogReturns' not in os.path.basename(p)\n",
    "]\n",
    "\n",
    "feature_names = [\n",
    "    os.path.splitext(os.path.basename(p))[0]\n",
    "    for p in feature_paths\n",
    "]\n",
    "\n",
    "exog_array = np.stack([np.load(p) for p in feature_paths], axis=-1)\n",
    "\n",
    "price_array = data.to_numpy()\n",
    "exog_array_with_price = np.concatenate(\n",
    "    [exog_array, price_array[:, :, np.newaxis]],\n",
    "    axis=-1\n",
    ")\n",
    "feature_names.append(\"price\")\n",
    "\n",
    "exog_dict_for_logReturns = {\n",
    "    f\"inst_{i}\": pd.DataFrame(\n",
    "        exog_array_with_price[:, i, :],\n",
    "        columns=feature_names\n",
    "    )\n",
    "    for i in range(exog_array_with_price.shape[1])\n",
    "}\n",
    "\n",
    "print(f\"Built exog_dict_for_logReturns with {len(exog_dict_for_logReturns)} instruments, each shape {exog_dict_for_logReturns['inst_0'].shape}\\n\")\n",
    "print(\"Features:\", feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Clean up the names of these features (scaler fits to each greek individually, we need to be able to then recreate the names of the greeks the same in our different program where predict log returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feature_name(name: str) -> str:\n",
    "    if name.startswith(\"LaggedPrices_Lag=\"):\n",
    "        lag = name.split(\"Lag=\")[1].split(\"_\")[0]\n",
    "        return f\"greek_lag_{lag}\"\n",
    "    elif name.startswith(\"Momentum_windowSize=\"):\n",
    "        win = name.split(\"windowSize=\")[1].split(\"_\")[0]\n",
    "        return f\"greek_momentum_{win}\"\n",
    "    elif name.startswith(\"Volatility_windowSize=\"):\n",
    "        win = name.split(\"windowSize=\")[1].split(\"_\")[0]\n",
    "        return f\"greek_volatility_{win}\"\n",
    "    elif name == \"price\":\n",
    "        return \"price\"\n",
    "    else:\n",
    "        return f\"greek_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cleaned names\n",
    "feature_names_clean = [clean_feature_name(name) for name in feature_names]\n",
    "\n",
    "# Build exog dictionary with clean names\n",
    "exog_dict_for_logReturns = {\n",
    "    f\"inst_{i}\": pd.DataFrame(\n",
    "        exog_array_with_price[:, i, :],\n",
    "        columns=feature_names_clean\n",
    "    )\n",
    "    for i in range(exog_array_with_price.shape[1])\n",
    "}\n",
    "\n",
    "print(\"Features:\", exog_dict_for_logReturns[\"inst_0\"].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Now split our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "logReturns_train = logReturns.loc[TRAIN_START:TRAIN_END - 1].copy()\n",
    "logReturns_val   = logReturns.loc[TRAIN_END:VAL_END - 1].copy()\n",
    "logReturns_test  = logReturns.loc[VAL_END:].copy()\n",
    "\n",
    "print(f\"Train days      : {logReturns_train.index.min()} --- {logReturns_train.index.max()}  (n={len(logReturns_train)})\")\n",
    "print(f\"Validation days : {logReturns_val.index.min()} --- {logReturns_val.index.max()}  (n={len(logReturns_val)})\")\n",
    "print(f\"Test days       : {logReturns_test.index.min()} --- {logReturns_test.index.max()}  (n={len(logReturns_test)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Now create this prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster_ms_greeks_logReturns = ForecasterRecursiveMultiSeries(\n",
    "    regressor           = GradientBoostingRegressor(random_state=8523),\n",
    "    lags                = 20,\n",
    "    transformer_series  = None,\n",
    "    transformer_exog    = StandardScaler(),  # Standardise the Greek features\n",
    ")\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size = len(logReturns_train) + len(logReturns_val),\n",
    "    steps              = 1,\n",
    "    refit              = True\n",
    ")\n",
    "\n",
    "# Backtest\n",
    "multi_series_mse_greeks_logReturns, predictions_ms_greeks_logReturns = backtesting_forecaster_multiseries(\n",
    "    forecaster = forecaster_ms_greeks_logReturns,\n",
    "    series     = logReturns,\n",
    "    exog       = exog_dict_for_logReturns,\n",
    "    levels     = list(logReturns.columns),\n",
    "    cv         = cv,\n",
    "    metric     = \"mean_squared_error\"\n",
    ")\n",
    "\n",
    "display(multi_series_mse_greeks_logReturns.head())\n",
    "display(predictions_ms_greeks_logReturns.head())\n",
    "\n",
    "multi_series_mse_greeks_logReturns = multi_series_mse_greeks_logReturns.rename(columns={\"mean_squared_error\": \"multi_series_mse_greeks_logReturns\"})\n",
    "predictions_ms_greeks_logReturns = predictions_ms_greeks_logReturns.reset_index()\n",
    "predictions_ms_greeks_logReturns = predictions_ms_greeks_logReturns.rename(columns={\"index\": \"time\"})\n",
    "\n",
    "print(f\"{colourOrangeBold} Average MSE across instruments: {multi_series_mse_greeks_logReturns['multi_series_mse_greeks_logReturns'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "And now plot our predicted log returns against the actual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPredictedVsActualLogReturns(predictions_input, instrument):\n",
    "    df_preds = predictions_input.copy().rename(columns={\"index\": \"time\"})\n",
    "    df_inst_preds = df_preds[df_preds[\"level\"] == instrument]\n",
    "    days_predicted = df_inst_preds[\"time\"]\n",
    "    df_actual = logReturns[[instrument]].copy()\n",
    "    df_actual[\"time\"] = df_actual.index\n",
    "    df_actual = df_actual.rename(columns={instrument: \"actual\"})\n",
    "    df_actual = df_actual[df_actual[\"time\"].isin(days_predicted)]\n",
    "    df_plot = df_inst_preds.merge(df_actual, on=\"time\")\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(df_plot[\"time\"], df_plot[\"actual\"], label=\"Actual LogReturn\", color='dodgerblue')\n",
    "    plt.plot(df_plot[\"time\"], df_plot[\"pred\"], label=\"Predicted LogReturn\", color='orange')\n",
    "    plt.title(f\"Predicted vs Actual LogReturns for {instrument}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Log Return\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plotPredictedVsActualLogReturns(predictions_ms_greeks_logReturns, \"inst_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    " We will consider this an optimal result for prediction and a baseline for future reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Convert predicted log returns to be the predicted next price. We can then compare this logReturns predicting model against our pricePredicting model/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_predict_from_logReturns = predictions_ms_greeks_logReturns.copy()\n",
    "\n",
    "# Rename predicted log return column temporarily\n",
    "price_predict_from_logReturns = price_predict_from_logReturns.rename(columns={\"pred\": \"predicted_logReturn\"})\n",
    "\n",
    "# Reconstruct predicted price using previous day's actual price\n",
    "def reconstruct_price(row):\n",
    "    instrument = row['level']\n",
    "    time = row['time']\n",
    "    if time == 0:\n",
    "        return np.nan  # Can't compute for first day\n",
    "    prev_price = data.loc[time - 1, instrument]\n",
    "    log_return = row['predicted_logReturn']\n",
    "    return prev_price * np.exp(log_return)\n",
    "\n",
    "# Apply the function to reconstruct price\n",
    "price_predict_from_logReturns[\"pred\"] = price_predict_from_logReturns.apply(reconstruct_price, axis=1)\n",
    "\n",
    "# Drop the original log return prediction\n",
    "price_predict_from_logReturns = price_predict_from_logReturns.drop(columns=[\"predicted_logReturn\"])\n",
    "\n",
    "display(price_predict_from_logReturns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Add actual prices from your price DataFrame (`data`)\n",
    "price_predict_from_logReturns[\"actual\"] = price_predict_from_logReturns.apply(\n",
    "    lambda row: data.loc[row[\"time\"], row[\"level\"]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "predictions_ms_greeks[\"actual\"] = predictions_ms_greeks.apply(\n",
    "    lambda row: data.loc[row[\"time\"], row[\"level\"]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "mse_logReturns = price_predict_from_logReturns.groupby(\"level\", group_keys=False).apply(\n",
    "    lambda g: mean_squared_error(g[\"actual\"], g[\"pred\"]),\n",
    "    include_groups=False\n",
    ").reset_index(name=\"mse_logReturns\")\n",
    "\n",
    "mse_greeks = predictions_ms_greeks.groupby(\"level\", group_keys=False).apply(\n",
    "    lambda g: mean_squared_error(g[\"actual\"], g[\"pred\"]),\n",
    "    include_groups=False\n",
    ").reset_index(name=\"mse_greeks\")\n",
    "\n",
    "# Merge and compute improvements\n",
    "mse_comparison = pd.merge(mse_logReturns, mse_greeks, on=\"level\")\n",
    "mse_comparison[\"improvement\"] = mse_comparison[\"mse_greeks\"] - mse_comparison[\"mse_logReturns\"]\n",
    "mse_comparison[\"improvement_(%)\"] = 100 * mse_comparison[\"improvement\"] / mse_comparison[\"mse_logReturns\"]\n",
    "mse_comparison = mse_comparison.round(4)\n",
    "\n",
    "# Style output\n",
    "display(mse_comparison.set_index(\"level\").style.bar(\n",
    "    subset=[\"improvement_(%)\"], align=\"mid\", color=[\"#d65f5f\", \"#5fba7d\"]\n",
    "))\n",
    "\n",
    "# Summary stats\n",
    "display(mse_comparison[[\"improvement\", \"improvement_(%)\"]].agg([\"mean\", \"min\", \"max\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Mostly big improvements from predicting prices to predicting log returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "Having the model retrain every time will exceed the 10 minute running length in the competition, we need to modify. A few options:\n",
    "- Change the regressor to HistGradientBoostingRegressor\n",
    "- Turn off refit\n",
    "- Somehow change refit to not refit everytime but instead every nth time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "HIST GRADIENT BOOSTING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster_ms_greeks_logReturns_hgbr = ForecasterRecursiveMultiSeries(\n",
    "    regressor           = HistGradientBoostingRegressor(random_state=8523),\n",
    "    lags                = 20,\n",
    "    transformer_series  = None,\n",
    "    transformer_exog    = StandardScaler(),  # Standardise the Greek features\n",
    ")\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size = len(logReturns_train) + len(logReturns_val),\n",
    "    steps              = 1,\n",
    "    refit              = True\n",
    ")\n",
    "\n",
    "# Backtest\n",
    "multi_series_mse_greeks_logReturns_hgbr, predictions_ms_greeks_logReturns_hgbr = backtesting_forecaster_multiseries(\n",
    "    forecaster = forecaster_ms_greeks_logReturns_hgbr,\n",
    "    series     = logReturns,\n",
    "    exog       = exog_dict_for_logReturns,\n",
    "    levels     = list(logReturns.columns),\n",
    "    cv         = cv,\n",
    "    metric     = \"mean_squared_error\"\n",
    ")\n",
    "\n",
    "display(multi_series_mse_greeks_logReturns_hgbr.head())\n",
    "display(predictions_ms_greeks_logReturns_hgbr.head())\n",
    "\n",
    "multi_series_mse_greeks_logReturns_hgbr = multi_series_mse_greeks_logReturns_hgbr.rename(columns={\"mean_squared_error\": \"multi_series_mse_greeks_logReturns_hgbr\"})\n",
    "predictions_ms_greeks_logReturns_hgbr = predictions_ms_greeks_logReturns_hgbr.reset_index()\n",
    "predictions_ms_greeks_logReturns_hgbr = predictions_ms_greeks_logReturns_hgbr.rename(columns={\"index\": \"time\"})\n",
    "\n",
    "print(f\"{colourOrangeBold} Average MSE across instruments: { multi_series_mse_greeks_logReturns_hgbr['multi_series_mse_greeks_logReturns_hgbr'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Compare HGBR to GBR (just using their log returns mse from now on because we will be predicting log returns)\n",
    ":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareModelToBaseline(new_model_mse, baselineModel = multi_series_mse_greeks_logReturns_hgbr):\n",
    "    # Join them\n",
    "    results = pd.merge(\n",
    "        baselineModel,\n",
    "        new_model_mse,\n",
    "        on=\"levels\",\n",
    "    )\n",
    "\n",
    "    # Rename for clarity\n",
    "    results.columns = [\"level\", \"BASELINE_MSE\", \"NEW_MSE\"]\n",
    "\n",
    "    # Calculate improvement of new over GBR\n",
    "    results[\"improvement\"] = results[\"BASELINE_MSE\"] - results[\"NEW_MSE\"]\n",
    "    results[\"improvement_(%)\"] = 100 * results[\"improvement\"] / results[\"BASELINE_MSE\"]\n",
    "\n",
    "    # Round and display\n",
    "    results = results.round(4)\n",
    "    display(results.style.bar(subset=['improvement_(%)'], align='mid', color=['#d65f5f', '#5fba7d']))\n",
    "    display(results[['improvement', 'improvement_(%)']].agg(['mean', 'min', 'max']))\n",
    "\n",
    "compareModelToBaseline(multi_series_mse_greeks_logReturns_hgbr, multi_series_mse_greeks_logReturns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "For some reason the HGBR is better than the GBR so lets use that as our new baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HGBR:\")\n",
    "plotPredictedVsActualLogReturns(predictions_ms_greeks_logReturns_hgbr, \"inst_0\")\n",
    "print(\"GBR:\")\n",
    "plotPredictedVsActualLogReturns(predictions_ms_greeks_logReturns, \"inst_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "Now a model without refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster_ms_greeks_logReturns = ForecasterRecursiveMultiSeries(\n",
    "    regressor           = GradientBoostingRegressor(random_state=8523),\n",
    "    lags                = 20,\n",
    "    transformer_series  = None,\n",
    "    transformer_exog    = StandardScaler(),  # Standardise the Greek features\n",
    ")\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size = len(logReturns_train) + len(logReturns_val),\n",
    "    steps              = 1,\n",
    "    refit              = False\n",
    ")\n",
    "\n",
    "# Backtest\n",
    "multi_series_mse_greeks_logReturns_noRefit, predictions_ms_greeks_logReturns_noRefit = backtesting_forecaster_multiseries(\n",
    "    forecaster = forecaster_ms_greeks_logReturns,\n",
    "    series     = logReturns,\n",
    "    exog       = exog_dict_for_logReturns,\n",
    "    levels     = list(logReturns.columns),\n",
    "    cv         = cv,\n",
    "    metric     = \"mean_squared_error\"\n",
    ")\n",
    "\n",
    "display(multi_series_mse_greeks_logReturns_noRefit.head())\n",
    "display(predictions_ms_greeks_logReturns_noRefit.head())\n",
    "\n",
    "multi_series_mse_greeks_logReturns_noRefit = multi_series_mse_greeks_logReturns_noRefit.rename(columns={\"mean_squared_error\": \"multi_series_mse_greeks_logReturns_noRefit\"})\n",
    "predictions_ms_greeks_logReturns_noRefit = predictions_ms_greeks_logReturns_noRefit.reset_index()\n",
    "predictions_ms_greeks_logReturns_noRefit = predictions_ms_greeks_logReturns_noRefit.rename(columns={\"index\": \"time\"})\n",
    "\n",
    "print(f\"{colourOrangeBold} Average MSE across instruments: {multi_series_mse_greeks_logReturns_noRefit['multi_series_mse_greeks_logReturns_noRefit'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Compare this to the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparing new model of 'GBR no refit' VS 'HGBR with refit'\")\n",
    "compareModelToBaseline(multi_series_mse_greeks_logReturns_noRefit, multi_series_mse_greeks_logReturns_hgbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Ok so its clear then that we should use HGBR as our primary choice. Now time for:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "Adding some rolling window features\n",
    "Allowed stats are:\n",
    "- mean\n",
    "- std\n",
    "- min\n",
    "- max\n",
    "- sum\n",
    "- median\n",
    "- ratio_min_max\n",
    "- coef_variation\n",
    "- ewm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_features = RollingFeatures(\n",
    "    stats           = ['min', 'max'],\n",
    "    window_sizes    = 10,\n",
    ")\n",
    "\n",
    "window_features_forecaster = ForecasterRecursiveMultiSeries(\n",
    "    regressor = HistGradientBoostingRegressor(random_state=8523),\n",
    "    transformer_series  = None,\n",
    "    transformer_exog    = StandardScaler(),\n",
    "    lags                = 20,\n",
    "    window_features     = window_features,\n",
    ")\n",
    "\n",
    "window_features_forecaster.dropna_from_series = True\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size  =len(logReturns_train) + len(logReturns_val),\n",
    "    steps               =1,\n",
    "    refit               =True\n",
    ")\n",
    "\n",
    "multi_series_mse_window, predictions_tuned_window = backtesting_forecaster_multiseries(\n",
    "    forecaster  = window_features_forecaster,\n",
    "    series      = logReturns,\n",
    "    exog        = exog_dict_for_logReturns,\n",
    "    levels      = list(logReturns.columns),\n",
    "    cv          = cv,\n",
    "    metric      = 'mean_squared_error',\n",
    ")\n",
    "\n",
    "multi_series_mse_window = multi_series_mse_window.rename(columns={\"mean_squared_error\": \"multi_series_mse_window\"})\n",
    "predictions_tuned_window = predictions_tuned_window.reset_index()\n",
    "predictions_tuned_window = predictions_tuned_window.rename(columns={\"index\": \"time\"})\n",
    "\n",
    "print(\"Window features: \", window_features.stats)\n",
    "print(\"Window length:   \", window_features.window_sizes)\n",
    "print(\n",
    "    f\"{colourOrangeBold} Average MSE across instruments: {multi_series_mse_window['multi_series_mse_window'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "\n",
    "### Ive tried a bunch of different combos, just min and max is the best.\n",
    "\n",
    "Also tried different scaler combinations. The best is\n",
    "series transformer = None\n",
    "exog transformer =  StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "Compare this to our baseline HGBR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparing new model of 'GBR with window' VS 'HGBR with refit'\")\n",
    "compareModelToBaseline(multi_series_mse_window, multi_series_mse_greeks_logReturns_hgbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "# HyperParameterTuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "### To get the most out of our model, tune the params.\n",
    "\n",
    "Params to tune:\n",
    "- Lags\n",
    "- Learning Rate\n",
    "- max_depth (max depth of tree in the ensemble) # Decided to not do\n",
    "- max_iter (number of trees in the ensemble) # Decided to not do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_space(trial):\n",
    "    return {\n",
    "        'lags': trial.suggest_categorical('lags', [7, 14]),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_features = RollingFeatures(\n",
    "    stats           = ['min', 'max'],\n",
    "    window_sizes    = 10,\n",
    ")\n",
    "\n",
    "forecaster_ms_tuning = ForecasterRecursiveMultiSeries(\n",
    "    regressor           = HistGradientBoostingRegressor(random_state=8523),\n",
    "    lags                = 20, # Should be overwritten by the search space\n",
    "    transformer_exog    = StandardScaler(),\n",
    "    transformer_series  = None,\n",
    "    encoding            = 'ordinal',\n",
    "    window_features     = window_features,\n",
    ")\n",
    "\n",
    "cv_search = TimeSeriesFold(\n",
    "    initial_train_size  = len(logReturns_train) + len(logReturns_val),\n",
    "    steps               = 1,\n",
    "    refit               = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bayesian search we need to change the shape of our exogs\n",
    "def flatten_exog_dict_to_wide_df(exog_dict):\n",
    "    dfs = []\n",
    "    for level, df in exog_dict.items():\n",
    "        renamed = df.copy()\n",
    "        renamed.columns = [f\"{level}__{col}\" for col in df.columns]\n",
    "        dfs.append(renamed)\n",
    "\n",
    "    # All have same number of rows, so just concat by columns\n",
    "    return pd.concat(dfs, axis=1)\n",
    "\n",
    "# Apply it\n",
    "exog_wide = flatten_exog_dict_to_wide_df(exog_dict_for_logReturns)\n",
    "print(\"exog_wide.shape:\", exog_wide.shape)  # Should be (750, many columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "#### Bayesian search for hyper param tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.model_selection import bayesian_search_forecaster_multiseries\n",
    "from skforecast.exceptions import OneStepAheadValidationWarning\n",
    "from skforecast.exceptions import MissingValuesWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=OneStepAheadValidationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=MissingValuesWarning)\n",
    "forecaster_ms_tuning.dropna_from_series = True\n",
    "\n",
    "results_df, best_trial = bayesian_search_forecaster_multiseries(\n",
    "    forecaster      = forecaster_ms_tuning,\n",
    "    series          = logReturns,\n",
    "    levels          = None,  # All instruments\n",
    "    exog            = exog_wide,\n",
    "    cv              = cv_search,\n",
    "    search_space    = search_space,\n",
    "    n_trials        = 40,\n",
    "    metric          = 'mean_squared_error',\n",
    "    return_best     = True, # results_df will contain the best fitting forecaster, params and metrics.\n",
    "    show_progress   = True,\n",
    ")\n",
    "\n",
    "best_idx = results_df['mean_squared_error__average'].idxmin()\n",
    "best_row = results_df.loc[best_idx]\n",
    "\n",
    "print(\"Best Trial Index:\", best_idx)\n",
    "print(\"Best Params:\", best_row['params'])\n",
    "print(\"Best Lags:\", best_row['lags'])\n",
    "print(\"Best MSE:\", best_row['mean_squared_error__average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_row['params']\n",
    "best_lags = best_row['lags']\n",
    "\n",
    "window_features = RollingFeatures(\n",
    "    stats           = ['min', 'max'],\n",
    "    window_sizes    = 10,\n",
    ")\n",
    "best_forecaster = ForecasterRecursiveMultiSeries(\n",
    "    regressor           = HistGradientBoostingRegressor(random_state=8523, **best_params),\n",
    "    transformer_series  = None,\n",
    "    transformer_exog    = StandardScaler(),\n",
    "    lags                = best_lags,\n",
    "    window_features     = window_features,\n",
    ")\n",
    "\n",
    "best_forecaster.dropna_from_series = True\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size  = len(logReturns_train) + len(logReturns_val),\n",
    "    steps               = 1,\n",
    "    refit               = False\n",
    ")\n",
    "\n",
    "multi_series_mse_tuned, predictions_tuned = backtesting_forecaster_multiseries(\n",
    "    forecaster  = best_forecaster,\n",
    "    series      = logReturns,\n",
    "    exog        = exog_dict_for_logReturns,\n",
    "    levels      = list(logReturns.columns),\n",
    "    cv          = cv,\n",
    "    metric      = 'mean_squared_error',\n",
    ")\n",
    "\n",
    "multi_series_mse_tuned = multi_series_mse_tuned.rename(columns={\"mean_squared_error\": \"multi_series_mse_tuned\"})\n",
    "predictions_tuned = predictions_tuned.reset_index()\n",
    "predictions_tuned = predictions_tuned.rename(columns={\"index\": \"time\"})\n",
    "\n",
    "print(f\"{colourOrangeBold} Average MSE across instruments: {multi_series_mse_tuned['multi_series_mse_tuned'].mean()}{colourOrangeBold}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "Now compare against our benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "compareModelToBaseline(multi_series_mse_tuned, multi_series_mse_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "Try predicting from training on the training set, predicting on the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get exog split\n",
    "\n",
    "exog_train = {\n",
    "    inst: df.iloc[TRAIN_START:TRAIN_END, :].copy()\n",
    "    for inst, df in exog_dict_for_logReturns.items()\n",
    "}\n",
    "\n",
    "exog_val = {\n",
    "    inst: df.iloc[TRAIN_END:VAL_END, :].copy()\n",
    "    for inst, df in exog_dict_for_logReturns.items()\n",
    "}\n",
    "\n",
    "exog_test = {\n",
    "    inst: df.iloc[VAL_END:, :].copy()\n",
    "    for inst, df in exog_dict_for_logReturns.items()\n",
    "}\n",
    "\n",
    "# quick sanity check\n",
    "print(\"Train shape:\", next(iter(exog_train.values())).shape)\n",
    "print(\"Val   shape:\",   next(iter(exog_val.values())).shape)\n",
    "print(\"Test  shape:\",   next(iter(exog_test.values())).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_features = RollingFeatures(\n",
    "    stats=['min', 'max'],\n",
    "    window_sizes=7,\n",
    ")\n",
    "\n",
    "print(f\"Lags = {best_lags}\")\n",
    "print(f\"Best_params = {best_params}\")\n",
    "testing_forecaster = ForecasterRecursiveMultiSeries(\n",
    "    regressor=HistGradientBoostingRegressor(random_state=8523, **best_params),\n",
    "    transformer_series=None,\n",
    "    transformer_exog=StandardScaler(),\n",
    "    lags=best_lags,\n",
    "    # window_features=window_features,\n",
    ")\n",
    "\n",
    "testing_forecaster.dropna_from_series = True\n",
    "\n",
    "testing_forecaster.fit(\n",
    "    series  = logReturns_train,\n",
    "    exog    = exog_train,\n",
    ")\n",
    "\n",
    "n_val_steps = next(iter(exog_val.values())).shape[0]\n",
    "\n",
    "predictions = testing_forecaster.predict(\n",
    "    steps       = n_val_steps, # predict all of the validation logReturns\n",
    "    last_window = logReturns_train.tail(10),\n",
    "    exog        = exog_val,\n",
    "    levels      = list(logReturns_val.columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_copy = predictions.reset_index().copy()\n",
    "\n",
    "predictions_copy.rename(columns={\n",
    "    \"index\": \"time\",\n",
    "    \"level_0\": \"level\"\n",
    "}, inplace=True)\n",
    "\n",
    "plotPredictedVsActualLogReturns(predictions_copy, \"inst_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "On average better by a tad but not really that much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "Plot predicted log returns against actual (and our benchmark too):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotPredictedVsActualLogReturns(predictions_tuned, \"inst_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "Cant really tell a difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "Save our best params to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Im not using the saved stuff anymore, too much effort\n",
    "\n",
    "best_forecaster.fit(\n",
    "    series  = logReturns,   # Train the forecaster on all of our data\n",
    "    exog    = exog_dict_for_logReturns,\n",
    ")\n",
    "\n",
    "fitted_scaler = best_forecaster.transformer_exog    # Save our fitted scaler\n",
    "\n",
    "\n",
    "model_package = {\n",
    "    \"best_params\": best_params,\n",
    "    \"best_lags\": best_lags,\n",
    "}\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"date-%Y-%m-%d_time-%H-%M-%S\")\n",
    "filepath = f\"./saved models/forecaster_model_{timestamp}.pkl\"\n",
    "\n",
    "# Save to file\n",
    "joblib.dump(\n",
    "    model_package,\n",
    "    filepath,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "Some ideas:\n",
    "- Predict vol over an n window and then steps = n as well to have a predictor of future volatilities of instruments for risk\n",
    "- Predict log returns with step 2 together with step 1. then if they oppose say next log return is > 0, and the one after is < 0, might be a bad idea to buy because of the trading tax or something"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
