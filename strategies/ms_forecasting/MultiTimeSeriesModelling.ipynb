{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-05T10:52:10.397018Z",
     "start_time": "2025-07-05T10:52:09.492668Z"
    }
   },
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from skforecast.plot import set_dark_theme\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn\n",
    "import skforecast\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from skforecast.recursive import ForecasterRecursive, ForecasterRecursiveMultiSeries\n",
    "from skforecast.model_selection import (\n",
    "    TimeSeriesFold,\n",
    "    OneStepAheadFold,\n",
    "    backtesting_forecaster,\n",
    "    bayesian_search_forecaster,\n",
    "    backtesting_forecaster_multiseries,\n",
    "    bayesian_search_forecaster_multiseries\n",
    ")\n",
    "from skforecast.preprocessing import RollingFeatures, series_long_to_dict, exog_long_to_dict\n",
    "from skforecast.exceptions import OneStepAheadValidationWarning\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ResourceWarning)\n",
    "\n",
    "colourOrangeBold = \"\\033[1m\\033[38;5;208m\"\n",
    "colourReset = \"\\033[0m\"\n",
    "\n",
    "print(f\"{colourOrangeBold}Version skforecast: {skforecast.__version__}{colourReset}\")\n",
    "print(f\"{colourOrangeBold}Version scikit-learn: {sklearn.__version__}{colourReset}\")\n",
    "print(f\"{colourOrangeBold}Version pandas: {pd.__version__}{colourReset}\")\n",
    "print(f\"{colourOrangeBold}Version numpy: {np.__version__}{colourReset}\")\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve()\n",
    "while project_root.name != \"Algothon-2025\" and project_root != project_root.parent:\n",
    "    project_root = project_root.parent\n",
    "\n",
    "os.chdir(project_root)\n",
    "print(\"Working directory set to:\", os.getcwd())\n",
    "\n",
    "set_dark_theme()"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_slice' from 'numpy._core.umath' (/Users/jensen/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/numpy/_core/umath.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplt\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mIPython\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdisplay\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m display\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mskforecast\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m set_dark_theme\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtqdm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/skforecast/plot/__init__.py:1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      2\u001B[39m     plot_residuals,\n\u001B[32m      3\u001B[39m     plot_multivariate_time_series_corr,\n\u001B[32m      4\u001B[39m     plot_prediction_distribution,\n\u001B[32m      5\u001B[39m     plot_prediction_intervals,\n\u001B[32m      6\u001B[39m     calculate_lag_autocorrelation,\n\u001B[32m      7\u001B[39m     set_dark_theme\n\u001B[32m      8\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/skforecast/plot/plot.py:12\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m check_optional_dependency\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     15\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/skforecast/utils/__init__.py:1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/skforecast/utils/utils.py:19\u001B[39m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlinear_model\u001B[39;00m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m clone\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpipeline\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Pipeline\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/sklearn/__init__.py:73\u001B[39m\n\u001B[32m     62\u001B[39m \u001B[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001B[39;00m\n\u001B[32m     63\u001B[39m \u001B[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001B[39;00m\n\u001B[32m     64\u001B[39m \u001B[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     67\u001B[39m \u001B[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001B[39;00m\n\u001B[32m     68\u001B[39m \u001B[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001B[39;00m\n\u001B[32m     69\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (  \u001B[38;5;66;03m# noqa: F401 E402\u001B[39;00m\n\u001B[32m     70\u001B[39m     __check_build,\n\u001B[32m     71\u001B[39m     _distributor_init,\n\u001B[32m     72\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m clone  \u001B[38;5;66;03m# noqa: E402\u001B[39;00m\n\u001B[32m     74\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_show_versions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m show_versions  \u001B[38;5;66;03m# noqa: E402\u001B[39;00m\n\u001B[32m     76\u001B[39m _submodules = [\n\u001B[32m     77\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcalibration\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     78\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcluster\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    114\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcompose\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    115\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/sklearn/base.py:19\u001B[39m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config_context, get_config\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexceptions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m InconsistentVersionWarning\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_estimator_html_repr\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_metadata_requests\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _MetadataRequester, _routing_enabled\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_param_validation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m validate_parameter_constraints\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/sklearn/utils/__init__.py:15\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _joblib, metadata_routing\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_bunch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Bunch\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_chunking\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m gen_batches, gen_even_slices\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_estimator_html_repr\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m estimator_html_repr\n\u001B[32m     18\u001B[39m \u001B[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001B[39;00m\n\u001B[32m     19\u001B[39m \u001B[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001B[39;00m\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001B[39;00m\n\u001B[32m     21\u001B[39m \u001B[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001B[39;00m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# `_` in its name.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/sklearn/utils/_chunking.py:11\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_config\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_param_validation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Interval, validate_params\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mchunk_generator\u001B[39m(gen, chunksize):\n\u001B[32m     15\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001B[39;00m\n\u001B[32m     16\u001B[39m \u001B[33;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:14\u001B[39m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumbers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Integral, Real\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msparse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m csr_matrix, issparse\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config_context, get_config\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mvalidation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _is_arraylike_not_scalar\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/scipy/sparse/__init__.py:300\u001B[39m\n\u001B[32m    294\u001B[39m \u001B[38;5;66;03m# Original code by Travis Oliphant.\u001B[39;00m\n\u001B[32m    295\u001B[39m \u001B[38;5;66;03m# Modified and extended by Ed Schofield, Robert Cimrman,\u001B[39;00m\n\u001B[32m    296\u001B[39m \u001B[38;5;66;03m# Nathan Bell, and Jake Vanderplas.\u001B[39;00m\n\u001B[32m    298\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mwarnings\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m_warnings\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m300\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_base\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n\u001B[32m    301\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_csr\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n\u001B[32m    302\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_csc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/scipy/sparse/_base.py:5\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[33;03m\"\"\"Base class for sparse matrices\"\"\"\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_sputils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (asmatrix, check_reshape_kwargs, check_shape,\n\u001B[32m      6\u001B[39m                        get_sum_dtype, isdense, isscalarlike,\n\u001B[32m      7\u001B[39m                        matrix, validateaxis, getdtype)\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_matrix\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m spmatrix\n\u001B[32m     11\u001B[39m __all__ = [\u001B[33m'\u001B[39m\u001B[33misspmatrix\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33missparse\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33msparray\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     12\u001B[39m            \u001B[33m'\u001B[39m\u001B[33mSparseWarning\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mSparseEfficiencyWarning\u001B[39m\u001B[33m'\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/scipy/sparse/_sputils.py:10\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmath\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m prod\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msparse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msp\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_lib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_util\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m np_long, np_ulong\n\u001B[32m     13\u001B[39m __all__ = [\u001B[33m'\u001B[39m\u001B[33mupcast\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mgetdtype\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mgetdata\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33misscalarlike\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33misintlike\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     14\u001B[39m            \u001B[33m'\u001B[39m\u001B[33misshape\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33missequence\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33misdense\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mismatrix\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mget_sum_dtype\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     15\u001B[39m            \u001B[33m'\u001B[39m\u001B[33mbroadcast_shapes\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     17\u001B[39m supported_dtypes = [np.bool_, np.byte, np.ubyte, np.short, np.ushort, np.intc,\n\u001B[32m     18\u001B[39m                     np.uintc, np_long, np_ulong, np.longlong, np.ulonglong,\n\u001B[32m     19\u001B[39m                     np.float32, np.float64, np.longdouble,\n\u001B[32m     20\u001B[39m                     np.complex64, np.complex128, np.clongdouble]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/scipy/_lib/_util.py:13\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TypeAlias, TypeVar\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_lib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_array_api\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m array_namespace, is_numpy, xp_size\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_lib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_docscrape\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FunctionDoc, Parameter\n\u001B[32m     17\u001B[39m AxisError: \u001B[38;5;28mtype\u001B[39m[\u001B[38;5;167;01mException\u001B[39;00m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/scipy/_lib/_array_api.py:18\u001B[39m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnpt\u001B[39;00m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_lib\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m array_api_compat\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_lib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01marray_api_compat\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     19\u001B[39m     is_array_api_obj,\n\u001B[32m     20\u001B[39m     size \u001B[38;5;28;01mas\u001B[39;00m xp_size,\n\u001B[32m     21\u001B[39m     numpy \u001B[38;5;28;01mas\u001B[39;00m np_compat,\n\u001B[32m     22\u001B[39m     device \u001B[38;5;28;01mas\u001B[39;00m xp_device,\n\u001B[32m     23\u001B[39m     is_numpy_namespace \u001B[38;5;28;01mas\u001B[39;00m is_numpy,\n\u001B[32m     24\u001B[39m     is_cupy_namespace \u001B[38;5;28;01mas\u001B[39;00m is_cupy,\n\u001B[32m     25\u001B[39m     is_torch_namespace \u001B[38;5;28;01mas\u001B[39;00m is_torch,\n\u001B[32m     26\u001B[39m     is_jax_namespace \u001B[38;5;28;01mas\u001B[39;00m is_jax,\n\u001B[32m     27\u001B[39m     is_array_api_strict_namespace \u001B[38;5;28;01mas\u001B[39;00m is_array_api_strict\n\u001B[32m     28\u001B[39m )\n\u001B[32m     30\u001B[39m __all__ = [\n\u001B[32m     31\u001B[39m     \u001B[33m'\u001B[39m\u001B[33m_asarray\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33marray_namespace\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33massert_almost_equal\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33massert_array_almost_equal\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     32\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mget_xp_devices\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     38\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mxp_take_along_axis\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mxp_unsupported_param_msg\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mxp_vector_norm\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     39\u001B[39m ]\n\u001B[32m     42\u001B[39m \u001B[38;5;66;03m# To enable array API and strict array-like input validation\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/scipy/_lib/array_api_compat/numpy/__init__.py:1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m * \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# from numpy import * doesn't overwrite these builtin names\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;28mabs\u001B[39m, \u001B[38;5;28mmax\u001B[39m, \u001B[38;5;28mmin\u001B[39m, \u001B[38;5;28mround\u001B[39m \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/numpy/__init__.py:379\u001B[39m, in \u001B[36m__getattr__\u001B[39m\u001B[34m(attr)\u001B[39m\n\u001B[32m    377\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_mac_os_check\u001B[39m():\n\u001B[32m    378\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m379\u001B[39m \u001B[33;03m    Quick Sanity check for Mac OS look for accelerate build bugs.\u001B[39;00m\n\u001B[32m    380\u001B[39m \u001B[33;03m    Testing numpy polyfit calls init_dgelsd(LAPACK)\u001B[39;00m\n\u001B[32m    381\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    382\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    383\u001B[39m         c = array([\u001B[32m3.\u001B[39m, \u001B[32m2.\u001B[39m, \u001B[32m1.\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/numpy/strings/__init__.py:1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mstrings\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mstrings\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m __all__, \u001B[34m__doc__\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/numpy/_core/strings.py:24\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmultiarray\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _vec_string\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01moverrides\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m array_function_dispatch, set_module\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mumath\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     25\u001B[39m     _center,\n\u001B[32m     26\u001B[39m     _expandtabs,\n\u001B[32m     27\u001B[39m     _expandtabs_length,\n\u001B[32m     28\u001B[39m     _ljust,\n\u001B[32m     29\u001B[39m     _lstrip_chars,\n\u001B[32m     30\u001B[39m     _lstrip_whitespace,\n\u001B[32m     31\u001B[39m     _partition,\n\u001B[32m     32\u001B[39m     _partition_index,\n\u001B[32m     33\u001B[39m     _replace,\n\u001B[32m     34\u001B[39m     _rjust,\n\u001B[32m     35\u001B[39m     _rpartition,\n\u001B[32m     36\u001B[39m     _rpartition_index,\n\u001B[32m     37\u001B[39m     _rstrip_chars,\n\u001B[32m     38\u001B[39m     _rstrip_whitespace,\n\u001B[32m     39\u001B[39m     _slice,\n\u001B[32m     40\u001B[39m     _strip_chars,\n\u001B[32m     41\u001B[39m     _strip_whitespace,\n\u001B[32m     42\u001B[39m     _zfill,\n\u001B[32m     43\u001B[39m     isalnum,\n\u001B[32m     44\u001B[39m     isalpha,\n\u001B[32m     45\u001B[39m     isdecimal,\n\u001B[32m     46\u001B[39m     isdigit,\n\u001B[32m     47\u001B[39m     islower,\n\u001B[32m     48\u001B[39m     isnumeric,\n\u001B[32m     49\u001B[39m     isspace,\n\u001B[32m     50\u001B[39m     istitle,\n\u001B[32m     51\u001B[39m     isupper,\n\u001B[32m     52\u001B[39m     str_len,\n\u001B[32m     53\u001B[39m )\n\u001B[32m     54\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mumath\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     55\u001B[39m     count \u001B[38;5;28;01mas\u001B[39;00m _count_ufunc,\n\u001B[32m     56\u001B[39m )\n\u001B[32m     57\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mumath\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     58\u001B[39m     endswith \u001B[38;5;28;01mas\u001B[39;00m _endswith_ufunc,\n\u001B[32m     59\u001B[39m )\n",
      "\u001B[31mImportError\u001B[39m: cannot import name '_slice' from 'numpy._core.umath' (/Users/jensen/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/numpy/_core/umath.py)"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set Training, Cross Validation and Testing Splits",
   "id": "2956987ad8a71855"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TRAIN_START = 20\n",
    "TRAIN_END = 600\n",
    "VAL_END = 675"
   ],
   "id": "cc2c5e64691bc739",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import our price data: Prices are what we are predicting",
   "id": "ac407001988f327d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# PRICES DATA:\n",
    "data = pd.read_csv(\"./sourceCode/prices.txt\", sep=r'\\s+', header=None)\n",
    "print(f\"{colourOrangeBold}Shape: {data.shape}{colourReset}\")"
   ],
   "id": "85720b28a61a95c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Add column names to prices data",
   "id": "e888e4500c137e28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data.index.name = 'day'\n",
    "data.columns = [f\"inst_{i}\" for i in range(data.shape[1])]"
   ],
   "id": "dde103d431db9c16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Split data into correct splits",
   "id": "7805e53d5e095549"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DATA SPLITTING:\n",
    "data_train = data.loc[TRAIN_START:TRAIN_END - 1].copy()\n",
    "data_val   = data.loc[TRAIN_END:VAL_END - 1].copy()\n",
    "data_test  = data.loc[VAL_END:].copy()\n",
    "\n",
    "print(f\"Train days      : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Validation days : {data_val.index.min()} --- {data_val.index.max()}  (n={len(data_val)})\")\n",
    "print(f\"Test days       : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")"
   ],
   "id": "2398165cf1c07a3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot prices data for a few instruments for fun",
   "id": "b1750dadb4ce722"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "instrumentCount = 4\n",
    "\n",
    "fig, axs = plt.subplots(instrumentCount, 1, figsize=(7, 5), sharex=True)\n",
    "data.iloc[:, :instrumentCount].plot(\n",
    "    legend=True,\n",
    "    subplots=True,\n",
    "    title='First 4 Instruments Prices Over Time',\n",
    "    ax=axs,\n",
    "    linewidth=1\n",
    ")\n",
    "# Add vertical lines at training and validation split\n",
    "for ax in axs:\n",
    "    ax.axvline(x=TRAIN_END, color='white', linestyle='--', linewidth=1)\n",
    "    ax.axvline(x=VAL_END, color='white', linestyle='--', linewidth=1)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "id": "548c373ad4fbb1b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train a forecaster that predicts prices for individual instruments for a baseline reference.",
   "id": "4814230e0b310605"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "items = []\n",
    "mse_values = []\n",
    "predictions = {}\n",
    "\n",
    "for i, item in enumerate(tqdm(data.columns)):\n",
    "    # Define forecaster\n",
    "    window_features = RollingFeatures(stats=['mean', 'min', 'max'], window_sizes=7)\n",
    "\n",
    "    forecaster = ForecasterRecursive(\n",
    "        regressor=HistGradientBoostingRegressor(random_state=8523),\n",
    "        lags=20,\n",
    "        window_features=window_features\n",
    "    )\n",
    "\n",
    "    # Backtesting forecaster\n",
    "    cv = TimeSeriesFold(\n",
    "        steps=1,\n",
    "        initial_train_size=len(data_train) + len(data_val),\n",
    "        refit=False,\n",
    "    )\n",
    "\n",
    "    metric, preds = backtesting_forecaster(\n",
    "        forecaster=forecaster,\n",
    "        y=data[item],\n",
    "        cv=cv,\n",
    "        metric='mean_squared_error',\n",
    "        show_progress=False\n",
    "    )\n",
    "\n",
    "    items.append(item)\n",
    "    mse_values.append(metric.at[0, 'mean_squared_error'])\n",
    "    predictions[item] = preds\n",
    "\n",
    "# Results\n",
    "uni_series_mse = pd.Series(\n",
    "    data=mse_values,\n",
    "    index=items,\n",
    "    name='uni_series_mse'\n",
    ")\n",
    "\n",
    "print(f\"{colourOrangeBold}========================{colourReset}\")\n",
    "print(uni_series_mse.head())\n",
    "print(f\"{colourOrangeBold}========================{colourReset}\\n\\n\")\n"
   ],
   "id": "3475bfbbe6ebe270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train a global / multi time series predictor that takes into account instrument correlation (Evaluated with the same backtester as the single instrument predictor):",
   "id": "4243b997dd186b52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "items = list(data.columns)\n",
    "\n",
    "# Define forecaster\n",
    "window_features = RollingFeatures(stats=['mean', 'min', 'max'], window_sizes=14)\n",
    "forecaster_ms = ForecasterRecursiveMultiSeries(\n",
    "    regressor           =GradientBoostingRegressor(random_state=8523), # ~ 20 seconds\n",
    "    # regressor           =HistGradientBoostingRegressor(random_state=8523), # Much quicker, slightly less accurate, nan safe\n",
    "    lags                =20,\n",
    "    encoding            ='ordinal',\n",
    "    transformer_series  =StandardScaler(),\n",
    "    window_features     =window_features,\n",
    ")\n",
    "\n",
    "# Backtesting forecaster for all items\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size  =len(data_train) + len(data_val),\n",
    "    steps               =1,   # Predict 7 steps ahead\n",
    "    refit               =True # Retrain at each split\n",
    ")\n",
    "\n",
    "multi_series_mse, predictions_ms = backtesting_forecaster_multiseries(\n",
    "    forecaster          =forecaster_ms,\n",
    "    series              =data,\n",
    "    levels              =items,\n",
    "    cv                  =cv,\n",
    "    metric              ='mean_squared_error',\n",
    ")\n",
    "\n",
    "# Results\n",
    "display(multi_series_mse.head(5))\n",
    "display(predictions_ms.head(5))\n",
    "\n",
    "predictions_ms = predictions_ms.reset_index()"
   ],
   "id": "4f6c9e7c9896ec6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Compare the global to unique predictors:",
   "id": "4b6eb804d36e7325"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "multi_series_mse = multi_series_mse.set_index('levels')\n",
    "multi_series_mse.columns = ['multi_series_mse']\n",
    "\n",
    "results = pd.concat((uni_series_mse, multi_series_mse), axis=1)\n",
    "results['improvement'] = results.eval('uni_series_mse - multi_series_mse')\n",
    "results['improvement_(%)'] = 100 * results.eval('(uni_series_mse - multi_series_mse) / uni_series_mse')\n",
    "results = results.round(2)\n",
    "\n",
    "display(results.style.bar(subset=['improvement_(%)'], align='mid', color=['#d65f5f', '#5fba7d']))\n",
    "display(results[['improvement', 'improvement_(%)']].agg(['mean', 'min', 'max']))\n"
   ],
   "id": "e707edfbc97b19f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using global predict:",
   "id": "9df87716f241d9ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plotPredictedVsActual(predictions_input, instrument):\n",
    "    df_preds = predictions_input.copy().rename(columns={\"index\": \"time\"})\n",
    "    df_inst_preds = df_preds[df_preds[\"level\"] == instrument]\n",
    "    days_predicted = df_inst_preds[\"time\"]\n",
    "    df_actual = data[[instrument]].copy()\n",
    "    df_actual[\"time\"] = df_actual.index\n",
    "    df_actual = df_actual.rename(columns={instrument: \"actual\"})\n",
    "    df_actual = df_actual[df_actual[\"time\"].isin(days_predicted)]\n",
    "    df_plot = df_inst_preds.merge(df_actual, on=\"time\")\n",
    "    display(df_plot)\n",
    "    # Step 4: Plot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(df_plot[\"time\"], df_plot[\"actual\"], label=\"Actual Price\", color='dodgerblue')\n",
    "    plt.plot(df_plot[\"time\"], df_plot[\"pred\"], label=\"Predicted Price\", color='orange')\n",
    "    plt.title(f\"Predicted vs Actual Prices for {instrument}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotPredictedVsActual(predictions_ms, \"inst_0\")\n"
   ],
   "id": "657e76ad5f0ed96e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Above looks decent but also a bit shite",
   "id": "563d2747747d9ad7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Now going to try adding more greeks to use in the model as exogenous features**\n",
   "id": "4565205a014be51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get exog features in a dictionary\n",
    "greeksFilePaths = sorted(glob.glob(\"./greeks/greeksData_750Days/*.npy\"))\n",
    "feature_names = [os.path.splitext(os.path.basename(f))[0] for f in greeksFilePaths]\n",
    "\n",
    "exog_array = np.stack([np.load(f) for f in greeksFilePaths], axis=-1)\n",
    "\n",
    "exog_dict = {\n",
    "    f\"inst_{i}\": pd.DataFrame(exog_array[:, i, :], columns=feature_names)\n",
    "    for i in range(exog_array.shape[1])\n",
    "}\n",
    "\n",
    "print(f\"{colourOrangeBold}Built exog_dict with {len(exog_dict)} instruments, each shape {exog_dict['inst_0'].shape}{colourReset}\")\n",
    "print(\"Features:\", feature_names)"
   ],
   "id": "f449dfa1292a514",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create our forecaster including these exogenous features\n",
   "id": "e101943263366c0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "forecaster_ms_greeks = ForecasterRecursiveMultiSeries(\n",
    "    regressor           = GradientBoostingRegressor(random_state=8523),\n",
    "    lags                = 20,\n",
    "    transformer_series  = StandardScaler(),\n",
    "    transformer_exog    = StandardScaler(),  # Standardise the Greek features\n",
    ")\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size = len(data_train) + len(data_val),\n",
    "    steps              = 1,\n",
    "    refit              = True\n",
    ")\n",
    "\n",
    "# Backtest\n",
    "multi_series_mse_greeks, predictions_ms_greeks = backtesting_forecaster_multiseries(\n",
    "    forecaster = forecaster_ms_greeks,\n",
    "    series     = data,\n",
    "    exog       = exog_dict,\n",
    "    levels     = list(data.columns),\n",
    "    cv         = cv,\n",
    "    metric     = \"mean_squared_error\"\n",
    ")\n",
    "\n",
    "display(multi_series_mse_greeks.head())\n",
    "display(predictions_ms_greeks.head())\n",
    "\n",
    "multi_series_mse_greeks = multi_series_mse_greeks.rename(columns={\"mean_squared_error\": \"multi_series_mse_greeks\"})\n",
    "predictions_ms_greeks = predictions_ms_greeks.reset_index()\n",
    "predictions_ms_greeks = predictions_ms_greeks.rename(columns={\"index\": \"time\"})"
   ],
   "id": "dc2e6679297e239f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Compare new predictions and plot new predictions vs Actual",
   "id": "f83573d4fbf536c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "multi_series_mse_greeks = multi_series_mse_greeks.set_index(\"levels\")\n",
    "# Join them\n",
    "results_greeks = pd.concat((multi_series_mse, multi_series_mse_greeks), axis=1)\n",
    "\n",
    "# Calculate improvements\n",
    "results_greeks['improvement'] = results_greeks.eval('multi_series_mse - multi_series_mse_greeks')\n",
    "results_greeks['improvement_(%)'] = 100 * results_greeks['improvement'] / results_greeks['multi_series_mse']\n",
    "results_greeks = results_greeks.round(2)\n",
    "\n",
    "# Display the goods\n",
    "display(results_greeks.style.bar(subset=['improvement_(%)'], align='mid', color=['#d65f5f', '#5fba7d']))\n",
    "display(results_greeks[['improvement', 'improvement_(%)']].agg(['mean', 'min', 'max']))"
   ],
   "id": "1fc850b6b58bb204",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plotPredictedVsActual(predictions_ms_greeks, \"inst_0\")",
   "id": "f67753b0a9e2b189",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now to try and predict log returns instead of prices:",
   "id": "f40bad423fd26527"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T10:13:31.051585Z",
     "start_time": "2025-07-05T01:25:06.199978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logReturns_np = np.load(\"./greeks/greeksData_750Days/LogReturns_lookback=1_750_day_data.npy\")\n",
    "logReturns = pd.DataFrame(logReturns_np)\n",
    "\n",
    "logReturns.columns = [f\"inst_{i}\" for i in range(logReturns.shape[1])]\n",
    "\n",
    "print(f\"{colourOrangeBold}Log returns shape = {colourReset}{logReturns.shape}\")"
   ],
   "id": "a02461f962ff2fef",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './greeks/greeksData_750Days/LogReturns_lookback=1_750_day_data.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m project_root.name != \u001B[33m\"\u001B[39m\u001B[33mAlgothon-2025\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m project_root != project_root.parent:\n\u001B[32m      8\u001B[39m     project_root = project_root.parent\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m logReturns_np = np.load(\u001B[33m\"\u001B[39m\u001B[33m./greeks/greeksData_750Days/LogReturns_lookback=1_750_day_data.npy\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     11\u001B[39m \u001B[38;5;28mprint\u001B[39m(logReturns_np.shape)\n\u001B[32m     12\u001B[39m logReturns = pd.DataFrame(logReturns_np)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Algothon-2025/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:451\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[39m\n\u001B[32m    449\u001B[39m     own_fid = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    450\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m451\u001B[39m     fid = stack.enter_context(\u001B[38;5;28mopen\u001B[39m(os.fspath(file), \u001B[33m\"\u001B[39m\u001B[33mrb\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m    452\u001B[39m     own_fid = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    454\u001B[39m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: './greeks/greeksData_750Days/LogReturns_lookback=1_750_day_data.npy'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create exogenous data (now with prices, laggedPrices and without logReturns (logReturns is used in predictions by lag))",
   "id": "dc81321bb19c041c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_paths = sorted(glob.glob(\"./greeks/greeksData_750Days/*.npy\"))\n",
    "\n",
    "feature_paths = [\n",
    "    p for p in all_paths\n",
    "    if 'LogReturns' not in os.path.basename(p)\n",
    "]\n",
    "\n",
    "feature_names = [\n",
    "    os.path.splitext(os.path.basename(p))[0]\n",
    "    for p in feature_paths\n",
    "]\n",
    "\n",
    "exog_array = np.stack([np.load(p) for p in feature_paths], axis=-1)\n",
    "\n",
    "price_array = data.to_numpy()\n",
    "exog_array_with_price = np.concatenate(\n",
    "    [exog_array, price_array[:, :, np.newaxis]],\n",
    "    axis=-1\n",
    ")\n",
    "feature_names.append(\"price\")\n",
    "\n",
    "exog_dict_for_logReturns = {\n",
    "    f\"inst_{i}\": pd.DataFrame(\n",
    "        exog_array_with_price[:, i, :],\n",
    "        columns=feature_names\n",
    "    )\n",
    "    for i in range(exog_array_with_price.shape[1])\n",
    "}\n",
    "\n",
    "print(f\"Built exog_dict_for_logReturns with {len(exog_dict_for_logReturns)} instruments, each shape {exog_dict_for_logReturns['inst_0'].shape}\\n\")\n",
    "print(\"Features:\", feature_names)"
   ],
   "id": "8cba823d6c19dab1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Clean up the names of these features (scaler fits to each greek individually, we need to be able to then recreate the names of the greeks the same in our different program where predict log returns)",
   "id": "12ade66394fd2481"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clean_feature_name(name: str) -> str:\n",
    "    if name.startswith(\"LaggedPrices_Lag=\"):\n",
    "        lag = name.split(\"Lag=\")[1].split(\"_\")[0]\n",
    "        return f\"greek_lag_{lag}\"\n",
    "    elif name.startswith(\"Momentum_windowSize=\"):\n",
    "        win = name.split(\"windowSize=\")[1].split(\"_\")[0]\n",
    "        return f\"greek_momentum_{win}\"\n",
    "    elif name.startswith(\"Volatility_windowSize=\"):\n",
    "        win = name.split(\"windowSize=\")[1].split(\"_\")[0]\n",
    "        return f\"greek_volatility_{win}\"\n",
    "    elif name == \"price\":\n",
    "        return \"price\"\n",
    "    else:\n",
    "        return f\"greek_{name}\""
   ],
   "id": "692009e32c568627",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate cleaned names\n",
    "feature_names_clean = [clean_feature_name(name) for name in feature_names]\n",
    "\n",
    "# Build exog dictionary with clean names\n",
    "exog_dict_for_logReturns = {\n",
    "    f\"inst_{i}\": pd.DataFrame(\n",
    "        exog_array_with_price[:, i, :],\n",
    "        columns=feature_names_clean\n",
    "    )\n",
    "    for i in range(exog_array_with_price.shape[1])\n",
    "}\n",
    "\n",
    "print(\"Features:\", exog_dict_for_logReturns[\"inst_0\"].columns.tolist())"
   ],
   "id": "98dde732d6ab1c04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now split our data",
   "id": "99986046fdd15dfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logReturns_train = data.loc[TRAIN_START:TRAIN_END - 1].copy()\n",
    "logReturns_val   = data.loc[TRAIN_END:VAL_END - 1].copy()\n",
    "logReturns_test  = data.loc[VAL_END:].copy()\n",
    "\n",
    "print(f\"Train days      : {logReturns_train.index.min()} --- {logReturns_train.index.max()}  (n={len(logReturns_train)})\")\n",
    "print(f\"Validation days : {logReturns_val.index.min()} --- {logReturns_val.index.max()}  (n={len(logReturns_val)})\")\n",
    "print(f\"Test days       : {logReturns_test.index.min()} --- {logReturns_test.index.max()}  (n={len(logReturns_test)})\")"
   ],
   "id": "fe7a0bfaffb4d8b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now create this prediction model",
   "id": "2e1e8bc9d0c81765"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "forecaster_ms_greeks_logReturns = ForecasterRecursiveMultiSeries(\n",
    "    regressor           = GradientBoostingRegressor(random_state=8523),\n",
    "    lags                = 20,\n",
    "    transformer_series  = None,\n",
    "    transformer_exog    = StandardScaler(),  # Standardise the Greek features\n",
    ")\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size = len(logReturns_train) + len(logReturns_val),\n",
    "    steps              = 1,\n",
    "    refit              = True\n",
    ")\n",
    "\n",
    "# Backtest\n",
    "multi_series_mse_greeks_logReturns, predictions_ms_greeks_logReturns = backtesting_forecaster_multiseries(\n",
    "    forecaster = forecaster_ms_greeks_logReturns,\n",
    "    series     = logReturns,\n",
    "    exog       = exog_dict_for_logReturns,\n",
    "    levels     = list(logReturns.columns),\n",
    "    cv         = cv,\n",
    "    metric     = \"mean_squared_error\"\n",
    ")\n",
    "\n",
    "display(multi_series_mse_greeks_logReturns.head())\n",
    "display(predictions_ms_greeks_logReturns.head())\n",
    "\n",
    "multi_series_mse_greeks_logReturns = multi_series_mse_greeks_logReturns.rename(columns={\"mean_squared_error\": \"multi_series_mse_greeks_logReturns\"})\n",
    "predictions_ms_greeks_logReturns = predictions_ms_greeks_logReturns.reset_index()\n",
    "predictions_ms_greeks_logReturns = predictions_ms_greeks_logReturns.rename(columns={\"index\": \"time\"})\n",
    "\n",
    "print(f\"{colourOrangeBold} Average MSE across instruments: {multi_series_mse_greeks_logReturns['multi_series_mse_greeks_logReturns'].mean()}\")"
   ],
   "id": "26791fc42cb2e779",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And now plot our predicted log returns against the actual:",
   "id": "67454f6c1775c197"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plotPredictedVsActualLogReturns(predictions_input, instrument):\n",
    "    df_preds = predictions_input.copy().rename(columns={\"index\": \"time\"})\n",
    "    df_inst_preds = df_preds[df_preds[\"level\"] == instrument]\n",
    "    days_predicted = df_inst_preds[\"time\"]\n",
    "    df_actual = logReturns[[instrument]].copy()\n",
    "    df_actual[\"time\"] = df_actual.index\n",
    "    df_actual = df_actual.rename(columns={instrument: \"actual\"})\n",
    "    df_actual = df_actual[df_actual[\"time\"].isin(days_predicted)]\n",
    "    df_plot = df_inst_preds.merge(df_actual, on=\"time\")\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(df_plot[\"time\"], df_plot[\"actual\"], label=\"Actual LogReturn\", color='dodgerblue')\n",
    "    plt.plot(df_plot[\"time\"], df_plot[\"pred\"], label=\"Predicted LogReturn\", color='orange')\n",
    "    plt.title(f\"Predicted vs Actual LogReturns for {instrument}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Log Return\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plotPredictedVsActualLogReturns(predictions_ms_greeks_logReturns, \"inst_0\")"
   ],
   "id": "890cc9d5f0542eda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " We will consider this an optimal result for prediction and a baseline for future reference",
   "id": "14a725d6b5e78a7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Convert predicted log returns to be the predicted next price. We can then compare this logReturns predicting model against our pricePredicting model/s",
   "id": "53f895626bbf1e40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "price_predict_from_logReturns = predictions_ms_greeks_logReturns.copy()\n",
    "\n",
    "# Rename predicted log return column temporarily\n",
    "price_predict_from_logReturns = price_predict_from_logReturns.rename(columns={\"pred\": \"predicted_logReturn\"})\n",
    "\n",
    "# Reconstruct predicted price using previous day's actual price\n",
    "def reconstruct_price(row):\n",
    "    instrument = row['level']\n",
    "    time = row['time']\n",
    "    if time == 0:\n",
    "        return np.nan  # Can't compute for first day\n",
    "    prev_price = data.loc[time - 1, instrument]\n",
    "    log_return = row['predicted_logReturn']\n",
    "    return prev_price * np.exp(log_return)\n",
    "\n",
    "# Apply the function to reconstruct price\n",
    "price_predict_from_logReturns[\"pred\"] = price_predict_from_logReturns.apply(reconstruct_price, axis=1)\n",
    "\n",
    "# Drop the original log return prediction\n",
    "price_predict_from_logReturns = price_predict_from_logReturns.drop(columns=[\"predicted_logReturn\"])\n",
    "\n",
    "display(price_predict_from_logReturns)"
   ],
   "id": "ab72e39c23395131",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Compare",
   "id": "51f6e0f28fd56d84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Add actual prices from your price DataFrame (`data`)\n",
    "price_predict_from_logReturns[\"actual\"] = price_predict_from_logReturns.apply(\n",
    "    lambda row: data.loc[row[\"time\"], row[\"level\"]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "predictions_ms_greeks[\"actual\"] = predictions_ms_greeks.apply(\n",
    "    lambda row: data.loc[row[\"time\"], row[\"level\"]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "mse_logReturns = price_predict_from_logReturns.groupby(\"level\", group_keys=False).apply(\n",
    "    lambda g: mean_squared_error(g[\"actual\"], g[\"pred\"]),\n",
    "    include_groups=False\n",
    ").reset_index(name=\"mse_logReturns\")\n",
    "\n",
    "mse_greeks = predictions_ms_greeks.groupby(\"level\", group_keys=False).apply(\n",
    "    lambda g: mean_squared_error(g[\"actual\"], g[\"pred\"]),\n",
    "    include_groups=False\n",
    ").reset_index(name=\"mse_greeks\")\n",
    "\n",
    "# Merge and compute improvements\n",
    "mse_comparison = pd.merge(mse_logReturns, mse_greeks, on=\"level\")\n",
    "mse_comparison[\"improvement\"] = mse_comparison[\"mse_greeks\"] - mse_comparison[\"mse_logReturns\"]\n",
    "mse_comparison[\"improvement_(%)\"] = 100 * mse_comparison[\"improvement\"] / mse_comparison[\"mse_logReturns\"]\n",
    "mse_comparison = mse_comparison.round(4)\n",
    "\n",
    "# Style output\n",
    "display(mse_comparison.set_index(\"level\").style.bar(\n",
    "    subset=[\"improvement_(%)\"], align=\"mid\", color=[\"#d65f5f\", \"#5fba7d\"]\n",
    "))\n",
    "\n",
    "# Summary stats\n",
    "display(mse_comparison[[\"improvement\", \"improvement_(%)\"]].agg([\"mean\", \"min\", \"max\"]))\n"
   ],
   "id": "bb1c71d47387b967",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Mostly big improvements from predicting prices to predicting log returns.\n",
   "id": "86f4229959eddfb8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Having the model retrain every time will exceed the 10 minute running length in the competition, we need to modify. A few options:\n",
    "- Change the regressor to HistGradientBoostingRegressor\n",
    "- Turn off refit\n",
    "- Somehow change refit to not refit everytime but instead every nth time"
   ],
   "id": "f3aca1955aafb82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "HIST GRADIENT BOOSTING:",
   "id": "a483298cf6ba7ff0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "forecaster_ms_greeks_logReturns_hgbr = ForecasterRecursiveMultiSeries(\n",
    "    regressor           = HistGradientBoostingRegressor(random_state=8523),\n",
    "    lags                = 20,\n",
    "    transformer_series  = None,\n",
    "    transformer_exog    = StandardScaler(),  # Standardise the Greek features\n",
    ")\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size = len(logReturns_train) + len(logReturns_val),\n",
    "    steps              = 1,\n",
    "    refit              = True\n",
    ")\n",
    "\n",
    "# Backtest\n",
    "multi_series_mse_greeks_logReturns_hgbr, predictions_ms_greeks_logReturns_hgbr = backtesting_forecaster_multiseries(\n",
    "    forecaster = forecaster_ms_greeks_logReturns_hgbr,\n",
    "    series     = logReturns,\n",
    "    exog       = exog_dict_for_logReturns,\n",
    "    levels     = list(logReturns.columns),\n",
    "    cv         = cv,\n",
    "    metric     = \"mean_squared_error\"\n",
    ")\n",
    "\n",
    "display(multi_series_mse_greeks_logReturns_hgbr.head())\n",
    "display(predictions_ms_greeks_logReturns_hgbr.head())\n",
    "\n",
    "multi_series_mse_greeks_logReturns_hgbr = multi_series_mse_greeks_logReturns_hgbr.rename(columns={\"mean_squared_error\": \"multi_series_mse_greeks_logReturns_hgbr\"})\n",
    "predictions_ms_greeks_logReturns_hgbr = predictions_ms_greeks_logReturns_hgbr.reset_index()\n",
    "predictions_ms_greeks_logReturns_hgbr = predictions_ms_greeks_logReturns_hgbr.rename(columns={\"index\": \"time\"})\n",
    "\n",
    "print(f\"{colourOrangeBold} Average MSE across instruments: { multi_series_mse_greeks_logReturns_hgbr['multi_series_mse_greeks_logReturns_hgbr'].mean()}\")"
   ],
   "id": "fbc32a0377ad3eca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Compare HGBR to GBR (just using their log returns mse from now on because we will be predicting log returns)\n",
    ":"
   ],
   "id": "f64e12e8e322b535"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compareModelToBaseline(new_model_mse, baselineModel = multi_series_mse_greeks_logReturns_hgbr):\n",
    "    # Join them\n",
    "    results = pd.merge(\n",
    "        baselineModel,\n",
    "        new_model_mse,\n",
    "        on=\"levels\",\n",
    "    )\n",
    "\n",
    "    # Rename for clarity\n",
    "    results.columns = [\"level\", \"BASELINE_MSE\", \"NEW_MSE\"]\n",
    "\n",
    "    # Calculate improvement of new over GBR\n",
    "    results[\"improvement\"] = results[\"BASELINE_MSE\"] - results[\"NEW_MSE\"]\n",
    "    results[\"improvement_(%)\"] = 100 * results[\"improvement\"] / results[\"BASELINE_MSE\"]\n",
    "\n",
    "    # Round and display\n",
    "    results = results.round(4)\n",
    "    display(results.style.bar(subset=['improvement_(%)'], align='mid', color=['#d65f5f', '#5fba7d']))\n",
    "    display(results[['improvement', 'improvement_(%)']].agg(['mean', 'min', 'max']))\n",
    "\n",
    "compareModelToBaseline(multi_series_mse_greeks_logReturns_hgbr, multi_series_mse_greeks_logReturns)"
   ],
   "id": "a88bf95a7b58bade",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For some reason the HGBR is better than the GBR so lets use that as our new baseline\n",
   "id": "a89d469934c71729"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"HGBR:\")\n",
    "plotPredictedVsActualLogReturns(predictions_ms_greeks_logReturns_hgbr, \"inst_0\")\n",
    "print(\"GBR:\")\n",
    "plotPredictedVsActualLogReturns(predictions_ms_greeks_logReturns, \"inst_0\")"
   ],
   "id": "48118bfb28701447",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now a model without refit",
   "id": "c8db8c9a7c6d17f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "forecaster_ms_greeks_logReturns = ForecasterRecursiveMultiSeries(\n",
    "    regressor           = GradientBoostingRegressor(random_state=8523),\n",
    "    lags                = 20,\n",
    "    transformer_series  = None,\n",
    "    transformer_exog    = StandardScaler(),  # Standardise the Greek features\n",
    ")\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size = len(logReturns_train) + len(logReturns_val),\n",
    "    steps              = 1,\n",
    "    refit              = False\n",
    ")\n",
    "\n",
    "# Backtest\n",
    "multi_series_mse_greeks_logReturns_noRefit, predictions_ms_greeks_logReturns_noRefit = backtesting_forecaster_multiseries(\n",
    "    forecaster = forecaster_ms_greeks_logReturns,\n",
    "    series     = logReturns,\n",
    "    exog       = exog_dict_for_logReturns,\n",
    "    levels     = list(logReturns.columns),\n",
    "    cv         = cv,\n",
    "    metric     = \"mean_squared_error\"\n",
    ")\n",
    "\n",
    "display(multi_series_mse_greeks_logReturns_noRefit.head())\n",
    "display(predictions_ms_greeks_logReturns_noRefit.head())\n",
    "\n",
    "multi_series_mse_greeks_logReturns_noRefit = multi_series_mse_greeks_logReturns_noRefit.rename(columns={\"mean_squared_error\": \"multi_series_mse_greeks_logReturns_noRefit\"})\n",
    "predictions_ms_greeks_logReturns_noRefit = predictions_ms_greeks_logReturns_noRefit.reset_index()\n",
    "predictions_ms_greeks_logReturns_noRefit = predictions_ms_greeks_logReturns_noRefit.rename(columns={\"index\": \"time\"})\n",
    "\n",
    "print(f\"{colourOrangeBold} Average MSE across instruments: {multi_series_mse_greeks_logReturns_noRefit['multi_series_mse_greeks_logReturns_noRefit'].mean()}\")"
   ],
   "id": "f1f77eec7dfea665",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Compare this to the best model:",
   "id": "e08b51adc4703103"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Comparing new model of 'GBR no refit' VS 'HGBR with refit'\")\n",
    "compareModelToBaseline(multi_series_mse_greeks_logReturns_noRefit, multi_series_mse_greeks_logReturns_hgbr)"
   ],
   "id": "d56a64ecafb320f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ok so its clear then that we should use HGBR as our primary choice. Now time for:",
   "id": "b3687a8f3cffaeed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Adding some rolling window features\n",
    "Allowed stats are:\n",
    "- mean\n",
    "- std\n",
    "- min\n",
    "- max\n",
    "- sum\n",
    "- median\n",
    "- ratio_min_max\n",
    "- coef_variation\n",
    "- ewm"
   ],
   "id": "da3e5f9eae3c5b2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "window_features = RollingFeatures(\n",
    "    stats           = ['min', 'max'],\n",
    "    window_sizes    = 10,\n",
    ")\n",
    "\n",
    "window_features_forecaster = ForecasterRecursiveMultiSeries(\n",
    "    regressor = HistGradientBoostingRegressor(random_state=8523),\n",
    "    transformer_series  = None,\n",
    "    transformer_exog    = StandardScaler(),\n",
    "    lags                = 20,\n",
    "    window_features     = window_features,\n",
    ")\n",
    "\n",
    "window_features_forecaster.dropna_from_series = True\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size  =len(logReturns_train) + len(logReturns_val),\n",
    "    steps               =1,\n",
    "    refit               =True\n",
    ")\n",
    "\n",
    "multi_series_mse_window, predictions_tuned_window = backtesting_forecaster_multiseries(\n",
    "    forecaster  = window_features_forecaster,\n",
    "    series      = logReturns,\n",
    "    exog        = exog_dict_for_logReturns,\n",
    "    levels      = list(logReturns.columns),\n",
    "    cv          = cv,\n",
    "    metric      = 'mean_squared_error',\n",
    ")\n",
    "\n",
    "multi_series_mse_window = multi_series_mse_window.rename(columns={\"mean_squared_error\": \"multi_series_mse_window\"})\n",
    "predictions_tuned_window = predictions_tuned_window.reset_index()\n",
    "predictions_tuned_window = predictions_tuned_window.rename(columns={\"index\": \"time\"})\n",
    "\n",
    "print(\"Window features: \", window_features.stats)\n",
    "print(\"Window length:   \", window_features.window_sizes)\n",
    "print(\n",
    "    f\"{colourOrangeBold} Average MSE across instruments: {multi_series_mse_window['multi_series_mse_window'].mean()}\")"
   ],
   "id": "88b3bb84723e0e49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Ive tried a bunch of different combos, just min and max is the best.\n",
    "\n",
    "Also tried different scaler combinations. The best is\n",
    "series transformer = None\n",
    "exog transformer =  StandardScaler()"
   ],
   "id": "be8999bc34628269"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Compare this to our baseline HGBR:",
   "id": "32e4f08ee2c0f99a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Comparing new model of 'GBR with window' VS 'HGBR with refit'\")\n",
    "compareModelToBaseline(multi_series_mse_window, multi_series_mse_greeks_logReturns_hgbr)"
   ],
   "id": "5ee07da4f5e1f1b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# HyperParameterTuning",
   "id": "408e1b90e05391ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### To get the most out of our model, tune the params.\n",
    "\n",
    "Params to tune:\n",
    "- Lags\n",
    "- Learning Rate\n",
    "- max_depth (max depth of tree in the ensemble) # Decided to not do\n",
    "- max_iter (number of trees in the ensemble) # Decided to not do"
   ],
   "id": "d0381e6ffd17f77d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def search_space(trial):\n",
    "    return {\n",
    "        'lags': trial.suggest_categorical('lags', [7, 14]),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "    }"
   ],
   "id": "f3021a49db44c5ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "window_features = RollingFeatures(\n",
    "    stats           = ['min', 'max'],\n",
    "    window_sizes    = 10,\n",
    ")\n",
    "\n",
    "forecaster_ms_tuning = ForecasterRecursiveMultiSeries(\n",
    "    regressor           = HistGradientBoostingRegressor(random_state=8523),\n",
    "    lags                = 20, # Should be overwritten by the search space\n",
    "    transformer_exog    = StandardScaler(),\n",
    "    transformer_series  = None,\n",
    "    encoding            = 'ordinal',\n",
    "    window_features     = window_features,\n",
    ")\n",
    "\n",
    "cv_search = TimeSeriesFold(\n",
    "    initial_train_size  = len(logReturns_train) + len(logReturns_val),\n",
    "    steps               = 1,\n",
    "    refit               = False\n",
    ")"
   ],
   "id": "3fe270d7f6472350",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For bayesian search we need to change the shape of our exogs\n",
    "def flatten_exog_dict_to_wide_df(exog_dict):\n",
    "    dfs = []\n",
    "    for level, df in exog_dict.items():\n",
    "        renamed = df.copy()\n",
    "        renamed.columns = [f\"{level}__{col}\" for col in df.columns]\n",
    "        dfs.append(renamed)\n",
    "\n",
    "    # All have same number of rows, so just concat by columns\n",
    "    return pd.concat(dfs, axis=1)\n",
    "\n",
    "# Apply it\n",
    "exog_wide = flatten_exog_dict_to_wide_df(exog_dict_for_logReturns)\n",
    "print(\"exog_wide.shape:\", exog_wide.shape)  # Should be (750, many columns)\n"
   ],
   "id": "c7cc564c2b01b13a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Bayesian search for hyper param tuning\n",
   "id": "1335753f32522e23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from skforecast.model_selection import bayesian_search_forecaster_multiseries\n",
    "from skforecast.exceptions import OneStepAheadValidationWarning\n",
    "from skforecast.exceptions import MissingValuesWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=OneStepAheadValidationWarning)\n",
    "warnings.simplefilter(\"ignore\", category=MissingValuesWarning)\n",
    "forecaster_ms_tuning.dropna_from_series = True\n",
    "\n",
    "results_df, best_trial = bayesian_search_forecaster_multiseries(\n",
    "    forecaster      = forecaster_ms_tuning,\n",
    "    series          = logReturns,\n",
    "    levels          = None,  # All instruments\n",
    "    exog            = exog_wide,\n",
    "    cv              = cv_search,\n",
    "    search_space    = search_space,\n",
    "    n_trials        = 40,\n",
    "    metric          = 'mean_squared_error',\n",
    "    return_best     = True, # results_df will contain the best fitting forecaster, params and metrics.\n",
    "    show_progress   = True,\n",
    ")\n",
    "\n",
    "best_idx = results_df['mean_squared_error__average'].idxmin()\n",
    "best_row = results_df.loc[best_idx]\n",
    "\n",
    "print(\"Best Trial Index:\", best_idx)\n",
    "print(\"Best Params:\", best_row['params'])\n",
    "print(\"Best Lags:\", best_row['lags'])\n",
    "print(\"Best MSE:\", best_row['mean_squared_error__average'])"
   ],
   "id": "64783e535ec645d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_params = best_row['params']\n",
    "best_lags = best_row['lags']\n",
    "\n",
    "window_features = RollingFeatures(\n",
    "    stats           = ['min', 'max'],\n",
    "    window_sizes    = 10,\n",
    ")\n",
    "best_forecaster = ForecasterRecursiveMultiSeries(\n",
    "    regressor           = HistGradientBoostingRegressor(random_state=8523, **best_params),\n",
    "    transformer_series  = None,\n",
    "    transformer_exog    = StandardScaler(),\n",
    "    lags                = best_lags,\n",
    "    window_features     = window_features,\n",
    ")\n",
    "\n",
    "best_forecaster.dropna_from_series = True\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    initial_train_size  = len(logReturns_train) + len(logReturns_val),\n",
    "    steps               = 1,\n",
    "    refit               = True\n",
    ")\n",
    "\n",
    "multi_series_mse_tuned, predictions_tuned = backtesting_forecaster_multiseries(\n",
    "    forecaster  = best_forecaster,\n",
    "    series      = logReturns,\n",
    "    exog        = exog_dict_for_logReturns,\n",
    "    levels      = list(logReturns.columns),\n",
    "    cv          = cv,\n",
    "    metric      = 'mean_squared_error',\n",
    ")\n",
    "\n",
    "multi_series_mse_tuned = multi_series_mse_tuned.rename(columns={\"mean_squared_error\": \"multi_series_mse_tuned\"})\n",
    "predictions_tuned = predictions_tuned.reset_index()\n",
    "predictions_tuned = predictions_tuned.rename(columns={\"index\": \"time\"})\n",
    "\n",
    "print(f\"{colourOrangeBold} Average MSE across instruments: {multi_series_mse_tuned['multi_series_mse_tuned'].mean()}{colourOrangeBold}\")\n"
   ],
   "id": "b0bba2b8b2d2dde4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now compare against our benchmark:",
   "id": "f4a53786f7e11d83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "compareModelToBaseline(multi_series_mse_tuned, multi_series_mse_window)",
   "id": "25b4e39197a372ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "On average better by a tad but not really that much.",
   "id": "cffe84610a1d3905"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot predicted log returns against actual (and our benchmark too):",
   "id": "639e775d0e449aea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plotPredictedVsActualLogReturns(predictions_tuned, \"inst_0\")\n",
    "plotPredictedVsActualLogReturns(predictions_ms_greeks_logReturns_hgbr, \"inst_0\")"
   ],
   "id": "9131d60514f65476",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cant really tell a difference",
   "id": "22f292a90b6dd97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save our best params to a file:",
   "id": "e08e63d06cf8ac7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "best_forecaster.fit(\n",
    "    series  = logReturns,   # Train the forecaster on all of our data\n",
    "    exog    = exog_dict_for_logReturns,\n",
    ")\n",
    "\n",
    "fitted_scaler = best_forecaster.transformer_exog    # Save our fitted scaler\n",
    "\n",
    "\n",
    "model_package = {\n",
    "    \"best_params\": best_params,\n",
    "    \"best_lags\": best_lags,\n",
    "}\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"date-%Y-%m-%d_time-%H-%M-%S\")\n",
    "filepath = f\"./saved models/forecaster_model_{timestamp}.pkl\"\n",
    "\n",
    "# Save to file\n",
    "joblib.dump(\n",
    "    model_package,\n",
    "    filepath,\n",
    ")"
   ],
   "id": "32d767867b13e48c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Some ideas:\n",
    "- Predict vol over an n window and then steps = n as well to have a predictor of future volatilities of instruments for risk\n",
    "- Predict log returns with step 2 together with step 1. then if they oppose say next log return is > 0, and the one after is < 0, might be a bad idea to buy because of the trading tax or something"
   ],
   "id": "5eae97339a9d7c77"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
